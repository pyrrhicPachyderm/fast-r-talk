<<child="theme.rnw">>=
@

%NB: Need to use [fragile] on frames with R chunks, or line breaks in printed code vanish.
%Also on frames with # in \url.

\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{texlogos}

<<include=F>>=
	benchmark <- function(expr) {
		cat(system.time(expr)[["elapsed"]])
	}
@

\title{Writing Faster R}
\author{
	Christopher Brown
}
\date{}

\begin{document}

\begin{frame}
	\titlepage
\end{frame}
\note[itemize]{
	\item
	There are a lot of us here who have to run code that takes a long time.
	We can save a lot of time by making it faster.
	
	\item
	R isn't naturally a fast language.
	But small changes can make a lot of difference.
	Just last week, I cut a program down from over 60 hours to just 1 hour by rewriting just one arithmetic function in it.
	
	\item
	We'll leap in with an example, to prove a point.
}

\begin{frame}[fragile]{Row Sums: Which is Faster?}
	<<>>=
		row_sums_apply <- function(mat) {
			apply(mat, 1, sum)
		}
	@
	
	<<>>=
		row_sums_loop <- function(mat) {
			result <- rep(0, nrow(mat))
			for(i in 1:ncol(mat)) {
				result <- result + mat[,i]
			}
			return(result)
		}
	@
\end{frame}
\note[itemize]{
	\item
	Explain both pieces of code.
	
	\item
	First uses apply, where 1 means apply over rows.
	
	\item
	Second creates an empty column with \texttt{rep}, then loops over each column and adds it on.
	
	\item
	Ask audience opinion on which will be faster.
	Get a poll.
}

\begin{frame}[fragile]{Row Sums: Benchmarks}
	\begin{uncoverenv}<+->
		<<>>=
			n <- 10000
			random_mat <- matrix(rnorm(n*n), nrow = n, ncol = n)
		@
	\end{uncoverenv}
	
	\begin{uncoverenv}<+->
		<<>>=
			benchmark(row_sums_apply(random_mat))
		@
		
		<<>>=
			benchmark(row_sums_loop(random_mat))
		@
	\end{uncoverenv}
	
	\begin{uncoverenv}<+->
		<<>>=
			benchmark(rowSums(random_mat))
		@
	\end{uncoverenv}
\end{frame}
\note[itemize]{
	\item
	Explain that we've created some dummy data.
	
	\item
	Counter to popular wisdom, the loop is faster.
	Popular wisdom is not wrong; loops are \emph{usually} slower.
	
	\item
	Will explain why this case is different later.
	For now, note that it pays to know what's going on under the hood.
}

\begin{frame}{Compiled or Interpreted}
	\begin{itemize}
		\item<+-> Compiled:
		\begin{itemize}
			\item C, {\cpluspluslogo}, C\#
			\item Rust
			\item Fortran
			\item Go
		\end{itemize}
		\item<.-> Interpreted:
		\begin{itemize}
			\item R
			\item Python
			\item MATLAB
			\item sh, bash, csh, zsh, etc.
		\end{itemize}
		\item<+-> Just-in-time compiled:
		\begin{itemize}
			\item Julia
			\item Java
		\end{itemize}
	\end{itemize}
\end{frame}
\note[itemize]{
	\item
	Explain compiled and interpreted.
	
	\item
	These are just some examples.
	
	\item
	In truth, this is kind of a continuum, and you can sometimes compile interpreted languages or vice versa.
	Just-in-time compiling is mid-way along this continuum, and Java and Julia each do it differently.
}

\begin{frame}[fragile]{What is Vectorising?}
	\begin{itemize}
		\item
		Running loops in C.
		
		\item
		See the source code of \texttt{colSums}:\\
		\url{https://github.com/wch/r-source/blob/b59f3f1a979ae4aeef87263384335b4e59b042b9/src/main/array.c#L1877}
	\end{itemize}
\end{frame}
\note[itemize]{
	\item
	You may well have heard the aphorism to vectorise your code.
	Why does this make things faster?
	
	\item
	It just runs the loops in C instead.
	
	\item
	See the source code for \texttt{colSums}.
	It's complicated, but at its core it's just a loop.
}

\end{document}
